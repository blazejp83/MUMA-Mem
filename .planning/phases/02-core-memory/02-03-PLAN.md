---
phase: 02-core-memory
plan: 03
type: execute
wave: 2
depends_on: ["02-01"]
files_modified: [src/pipeline/extract.ts, src/pipeline/construct.ts, src/pipeline/retrieve.ts, src/pipeline/decide.ts]
autonomous: true
---

<objective>
Implement the four core write pipeline steps: Extract, Construct, Retrieve, and Decide.

Purpose: The write pipeline processes raw agent input into structured memories. Extract pulls facts via LLM, Construct builds the note object, Retrieve finds similar existing notes, and Decide determines the write operation (ADD/UPDATE/DELETE/NOOP). This covers PIPE-01 through PIPE-04.
Output: Four step functions that will be composed by the pipeline orchestrator (Plan 05).
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@src/types/note.ts
@src/types/store.ts
@src/llm/provider.ts
@src/embedding/types.ts
@src/config.ts
@src/plugin.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement Extract and Construct steps</name>
  <files>src/pipeline/extract.ts, src/pipeline/construct.ts</files>
  <action>
**src/pipeline/extract.ts — PIPE-01: Extract structured facts from input via LLM**

Export:
```typescript
export interface ExtractedFacts {
  facts: string[];           // Individual factual statements extracted
  keywords: string[];        // 3-7 keywords ordered by salience
  tags: string[];            // 3-5 categorical labels
  context: string;           // One-sentence semantic summary
  visibility: Visibility;    // LLM-classified access scope
  importance: number;        // 0-1 importance score
  domain: string;            // Topical classification (e.g., "business/sales")
}

export async function extract(
  input: string,
  llm: LLMProvider,
): Promise<ExtractedFacts>
```

Implementation:
- Call llm.generateJSON() with a system prompt that instructs the LLM to:
  1. Extract individual factual statements from the input
  2. Generate 3-7 keywords ordered by salience
  3. Generate 3-5 categorical tags
  4. Write a one-sentence semantic summary (context)
  5. Classify visibility: "open" for general facts/preferences, "scoped" for domain-specific work, "private" for sensitive personal info
  6. Score importance 0-1 (routine=0.3, notable=0.5, significant=0.7, critical=0.9)
  7. Classify domain as hierarchical path (e.g., "business/sales", "personal/health", "coding/typescript")
- System prompt should be a template literal, not loaded from file
- If LLM returns invalid JSON or missing fields, provide sensible defaults (visibility="scoped", importance=0.5, domain="general", empty arrays for missing lists)
- The input is the raw text from the agent — could be a message, observation, or tool output

**src/pipeline/construct.ts — PIPE-02: Construct NoteCreate from extracted facts**

Export:
```typescript
export interface ConstructOptions {
  userId: string;
  agentId: string;
  source?: MemorySource;     // Default "experience"
}

export async function construct(
  facts: ExtractedFacts,
  embedding: EmbeddingProvider,
  options: ConstructOptions,
): Promise<NoteCreate>
```

Implementation:
- Combine facts.facts into a single content string (join with ". " if multiple facts, or use the first fact if only one)
- Generate embedding: `await embedding.embed(content)`
- Build NoteCreate object mapping ExtractedFacts fields to NoteCreate fields:
  - content: combined facts string
  - context: facts.context
  - keywords: facts.keywords
  - tags: facts.tags
  - embedding: generated embedding
  - links: [] (empty — linking happens in a later step)
  - created_by: options.agentId
  - user_id: options.userId
  - domain: facts.domain
  - visibility: facts.visibility
  - importance: facts.importance
  - source: options.source ?? "experience"
  - confidence: 0.8 (default for LLM-extracted facts; can be refined later)
  </action>
  <verify>npx tsc --noEmit passes</verify>
  <done>extract() returns structured facts from raw input via LLM; construct() builds NoteCreate with embedding from extracted facts</done>
</task>

<task type="auto">
  <name>Task 2: Implement Retrieve and Decide steps</name>
  <files>src/pipeline/retrieve.ts, src/pipeline/decide.ts</files>
  <action>
**src/pipeline/retrieve.ts — PIPE-03: Retrieve similar existing notes**

Export:
```typescript
export async function retrieve(
  noteCreate: NoteCreate,
  store: MemoryStore,
  topK?: number,
): Promise<VectorSearchResult[]>
```

Implementation:
- Call store.search() with the new note's embedding, userId from noteCreate.user_id, topK (default 10)
- Return the results as-is (sorted by similarity score)
- This is a thin wrapper — the purpose is to give the pipeline a named step with a clear interface

**src/pipeline/decide.ts — PIPE-04: Decide write operation**

Export:
```typescript
export interface WriteDecision {
  operation: WriteOperation;   // "ADD" | "UPDATE" | "DELETE" | "NOOP"
  targetNoteId?: string;       // ID of existing note to UPDATE or DELETE (undefined for ADD/NOOP)
  reason: string;              // LLM explanation for the decision
  mergedContent?: string;      // For UPDATE: the merged content combining old + new
}

export async function decide(
  noteCreate: NoteCreate,
  similar: VectorSearchResult[],
  llm: LLMProvider,
): Promise<WriteDecision>
```

Implementation:
- If similar is empty (no existing notes), return { operation: "ADD", reason: "No similar memories found" }
- Otherwise, call llm.generateJSON() with:
  - System prompt explaining the four operations:
    - ADD: No semantic equivalent exists. New distinct information.
    - UPDATE: An existing note covers the same topic but new info adds to it. Return targetNoteId + merged content.
    - DELETE: New info directly contradicts and supersedes an existing note. Return targetNoteId.
    - NOOP: Information already captured adequately. Return targetNoteId of the existing note that covers it.
  - User prompt containing:
    - The new note's content, context, keywords
    - Each similar note's id, content, context, keywords, and similarity score
  - Ask LLM to respond with JSON: { operation, targetNoteId, reason, mergedContent }
- Validate response: operation must be one of the four. If targetNoteId provided, it must match one of the similar note IDs. Default to ADD if validation fails.
- For UPDATE: mergedContent should combine the existing note's content with new information (LLM generates this)
- For NOOP: the pipeline will bump the existing note's access count
  </action>
  <verify>npx tsc --noEmit passes</verify>
  <done>retrieve() finds similar existing notes; decide() returns LLM-determined write operation (ADD/UPDATE/DELETE/NOOP) with target and reason</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `npx tsc --noEmit` succeeds
- [ ] Four step functions exported: extract(), construct(), retrieve(), decide()
- [ ] extract() uses LLM generateJSON for structured fact extraction
- [ ] construct() generates embedding and builds NoteCreate
- [ ] retrieve() wraps store.search with note's embedding
- [ ] decide() uses LLM to determine ADD/UPDATE/DELETE/NOOP
- [ ] All functions are standalone (no cross-imports between step files)
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- Each step function takes explicit dependencies as parameters (not global state)
- LLM prompts are clear and produce valid JSON output
- Graceful fallback when LLM returns invalid data (default to ADD)
  </success_criteria>

<output>
After completion, create `.planning/phases/02-core-memory/02-03-SUMMARY.md`
</output>
